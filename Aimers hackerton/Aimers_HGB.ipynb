{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/sola/Downloads/open/train.csv')\n",
    "test_df = pd.read_csv('/Users/sola/Downloads/open/test.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/js/792bsrvx24lcg4nrdgy7k5br0000gn/T/ipykernel_10134/1987006743.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_df=train_df.fillna(train_df.mean())\n",
      "/var/folders/js/792bsrvx24lcg4nrdgy7k5br0000gn/T/ipykernel_10134/1987006743.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test_df=test_df.fillna(test_df.mean())\n"
     ]
    }
   ],
   "source": [
    "# 결측치에 평균 넣어주기\n",
    "train_df=train_df.fillna(train_df.mean())\n",
    "test_df=test_df.fillna(test_df.mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0      0.0\n1      0.0\n2      0.0\n3      0.0\n4      0.0\n      ... \n593    0.0\n594    0.0\n595    0.0\n596    0.0\n597    0.0\nName: X_2875, Length: 598, dtype: float64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['X_2875']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_3', 'X_6', 'X_14', 'X_70', 'X_74', 'X_75', 'X_76', 'X_77', 'X_78', 'X_79', 'X_82', 'X_83', 'X_84', 'X_85', 'X_142', 'X_190', 'X_191', 'X_192', 'X_193', 'X_194', 'X_195', 'X_232', 'X_234', 'X_235', 'X_259', 'X_260', 'X_315', 'X_319', 'X_322', 'X_323', 'X_324', 'X_327', 'X_328', 'X_329', 'X_330', 'X_375', 'X_376', 'X_377', 'X_378', 'X_427', 'X_466', 'X_467', 'X_505', 'X_508', 'X_558', 'X_561', 'X_567', 'X_583', 'X_617', 'X_620', 'X_631', 'X_633', 'X_634', 'X_636', 'X_638', 'X_639', 'X_640', 'X_641', 'X_642', 'X_672', 'X_673', 'X_676', 'X_691', 'X_692', 'X_695', 'X_715', 'X_729', 'X_732', 'X_743', 'X_749', 'X_759', 'X_760', 'X_761', 'X_764', 'X_776', 'X_777', 'X_778', 'X_836', 'X_843', 'X_844', 'X_849', 'X_859', 'X_886', 'X_887', 'X_888', 'X_889', 'X_934', 'X_935', 'X_936', 'X_937', 'X_992', 'X_1020', 'X_1021', 'X_1022', 'X_1023', 'X_1024', 'X_1025', 'X_1070', 'X_1092', 'X_1119', 'X_1137', 'X_1146', 'X_1206', 'X_1216', 'X_1219', 'X_1248', 'X_1249', 'X_1250', 'X_1251', 'X_1252', 'X_1253', 'X_1255', 'X_1293', 'X_1298', 'X_1309', 'X_1311', 'X_1312', 'X_1314', 'X_1316', 'X_1317', 'X_1318', 'X_1319', 'X_1320', 'X_1361', 'X_1362', 'X_1363', 'X_1364', 'X_1367', 'X_1392', 'X_1393', 'X_1394', 'X_1395', 'X_1396', 'X_1399', 'X_1426', 'X_1457', 'X_1487', 'X_1502', 'X_1503', 'X_1504', 'X_1522', 'X_1531', 'X_1537', 'X_1571', 'X_1572', 'X_1573', 'X_1574', 'X_1575', 'X_1576', 'X_1577', 'X_1578', 'X_1579', 'X_1580', 'X_1581', 'X_1582', 'X_1644', 'X_1645', 'X_1688', 'X_1689', 'X_1692', 'X_1693', 'X_1702', 'X_1722', 'X_1723', 'X_1724', 'X_1754', 'X_1760', 'X_1766', 'X_1772', 'X_1778', 'X_1784', 'X_1790', 'X_1796', 'X_1802', 'X_1808', 'X_1828', 'X_1835', 'X_1836', 'X_1837', 'X_1838', 'X_1839', 'X_1840', 'X_1841', 'X_1842', 'X_1844', 'X_1845', 'X_1846', 'X_1847', 'X_1848', 'X_1851', 'X_1852', 'X_1869', 'X_1870', 'X_1871', 'X_1872', 'X_2052', 'X_2053', 'X_2054', 'X_2055', 'X_2420', 'X_2462', 'X_2628', 'X_2629', 'X_2630', 'X_2631', 'X_2632', 'X_2633', 'X_2634', 'X_2635', 'X_2636', 'X_2637', 'X_2638', 'X_2639', 'X_2640', 'X_2641', 'X_2642', 'X_2643', 'X_2644', 'X_2645', 'X_2646', 'X_2647', 'X_2648', 'X_2649', 'X_2650', 'X_2651', 'X_2652', 'X_2653', 'X_2654', 'X_2655', 'X_2656', 'X_2657', 'X_2658', 'X_2659', 'X_2660', 'X_2661', 'X_2662', 'X_2663', 'X_2664', 'X_2665', 'X_2666', 'X_2667', 'X_2668', 'X_2669', 'X_2670', 'X_2671', 'X_2672', 'X_2673', 'X_2674', 'X_2675', 'X_2676', 'X_2677', 'X_2678', 'X_2679', 'X_2680', 'X_2681', 'X_2682', 'X_2683', 'X_2684', 'X_2685', 'X_2686', 'X_2687', 'X_2688', 'X_2689', 'X_2690', 'X_2691', 'X_2692', 'X_2693', 'X_2694', 'X_2695', 'X_2696', 'X_2697', 'X_2698', 'X_2699', 'X_2733', 'X_2775', 'X_2838', 'X_2844', 'X_2872', 'X_2873', 'X_2874', 'X_2875']\n"
     ]
    }
   ],
   "source": [
    "# 모든 값이 0인 피처 지울거임..\n",
    "wrong = []\n",
    "for i in range(1,2876):\n",
    "    ch = 'X_'+str(i)\n",
    "    if train_df[ch].mean() == 0:\n",
    "        wrong.append(ch)\n",
    "\n",
    "print(wrong)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
    "train_x = train_x.drop(columns=wrong) # 평균이 0인 컬럼은 지움\n",
    "train_y = train_df['Y_Class']\n",
    "\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP']) # 평균이 0인 컬럼은 지움\n",
    "test_x = test_x.drop(columns=wrong)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# 범주형을 수치형으로 변환하는 과정\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "\n",
    "    for label in np.unique(test_x[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i])\n",
    "print('Done.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "     LINE  PRODUCT_CODE        X_1        X_2   X_4       X_5        X_7  \\\n0       2             0   2.409742  95.123209  45.0  10.39255  48.802292   \n1       3             0   2.409742  95.123209  45.0  10.39255  48.802292   \n2       2             0   2.409742  95.123209  45.0  10.39255  48.802292   \n3       3             0   2.409742  95.123209  45.0  10.39255  48.802292   \n4       2             0   2.409742  95.123209  45.0  10.39255  48.802292   \n..    ...           ...        ...        ...   ...       ...        ...   \n593     5             2   2.000000  95.000000  45.0  10.00000  50.000000   \n594     2             0   2.409742  95.123209  45.0  10.39255  48.802292   \n595     2             0   2.409742  95.123209  45.0  10.39255  48.802292   \n596     4             1  40.000000  94.000000  45.0  11.00000  45.000000   \n597     5             1  21.000000  87.000000  45.0  10.00000  61.000000   \n\n           X_8        X_9  X_10  ...      X_2862      X_2863      X_2864  \\\n0    10.048711  41.469914   2.0  ...  189.000000  383.000000  368.296296   \n1    10.048711  41.469914   2.0  ...  185.600000  383.000000  367.735849   \n2    10.048711  41.469914   2.0  ...  165.500000  383.000000  367.320755   \n3    10.048711  41.469914   2.0  ...  165.800000  384.000000  369.188679   \n4    10.048711  41.469914   2.0  ...  182.600000  383.000000  367.351852   \n..         ...        ...   ...  ...         ...         ...         ...   \n593  10.000000  52.000000   2.0  ...  163.290763  423.558233  406.088187   \n594  10.048711  41.469914   2.0  ...  168.700000  384.000000  369.811321   \n595  10.048711  41.469914   2.0  ...  156.600000  383.000000  367.018868   \n596  10.000000  31.000000   2.0  ...  163.290763  423.558233  406.088187   \n597  10.000000  52.000000   2.0  ...  163.290763  423.558233  406.088187   \n\n         X_2865   X_2866   X_2867   X_2868   X_2869   X_2870  X_2871  \n0    353.000000  39.3400  40.8900  32.5600  34.0900  77.7700     1.0  \n1    353.000000  38.8900  42.8200  43.9200  35.3400  72.5500     1.0  \n2    353.000000  39.1900  36.6500  42.4700  36.5300  78.3500     1.0  \n3    353.000000  37.7400  39.1700  52.1700  30.5800  71.7800     1.0  \n4    352.000000  38.7000  41.8900  46.9300  33.0900  76.9700     1.0  \n..          ...      ...      ...      ...      ...      ...     ...  \n593  388.064257  50.8073  53.6077  49.6062  51.6598  66.6497     1.0  \n594  353.000000  49.4700  53.0700  50.8900  55.1000  66.4900     1.0  \n595  352.000000  50.8073  53.6077  49.6062  51.6598  66.6497     1.0  \n596  388.064257  50.8073  53.6077  49.6062  51.6598  66.6497     1.0  \n597  388.064257  50.8073  53.6077  49.6062  51.6598  66.6497     1.0  \n\n[598 rows x 2596 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LINE</th>\n      <th>PRODUCT_CODE</th>\n      <th>X_1</th>\n      <th>X_2</th>\n      <th>X_4</th>\n      <th>X_5</th>\n      <th>X_7</th>\n      <th>X_8</th>\n      <th>X_9</th>\n      <th>X_10</th>\n      <th>...</th>\n      <th>X_2862</th>\n      <th>X_2863</th>\n      <th>X_2864</th>\n      <th>X_2865</th>\n      <th>X_2866</th>\n      <th>X_2867</th>\n      <th>X_2868</th>\n      <th>X_2869</th>\n      <th>X_2870</th>\n      <th>X_2871</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2.409742</td>\n      <td>95.123209</td>\n      <td>45.0</td>\n      <td>10.39255</td>\n      <td>48.802292</td>\n      <td>10.048711</td>\n      <td>41.469914</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>189.000000</td>\n      <td>383.000000</td>\n      <td>368.296296</td>\n      <td>353.000000</td>\n      <td>39.3400</td>\n      <td>40.8900</td>\n      <td>32.5600</td>\n      <td>34.0900</td>\n      <td>77.7700</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2.409742</td>\n      <td>95.123209</td>\n      <td>45.0</td>\n      <td>10.39255</td>\n      <td>48.802292</td>\n      <td>10.048711</td>\n      <td>41.469914</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>185.600000</td>\n      <td>383.000000</td>\n      <td>367.735849</td>\n      <td>353.000000</td>\n      <td>38.8900</td>\n      <td>42.8200</td>\n      <td>43.9200</td>\n      <td>35.3400</td>\n      <td>72.5500</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2.409742</td>\n      <td>95.123209</td>\n      <td>45.0</td>\n      <td>10.39255</td>\n      <td>48.802292</td>\n      <td>10.048711</td>\n      <td>41.469914</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>165.500000</td>\n      <td>383.000000</td>\n      <td>367.320755</td>\n      <td>353.000000</td>\n      <td>39.1900</td>\n      <td>36.6500</td>\n      <td>42.4700</td>\n      <td>36.5300</td>\n      <td>78.3500</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2.409742</td>\n      <td>95.123209</td>\n      <td>45.0</td>\n      <td>10.39255</td>\n      <td>48.802292</td>\n      <td>10.048711</td>\n      <td>41.469914</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>165.800000</td>\n      <td>384.000000</td>\n      <td>369.188679</td>\n      <td>353.000000</td>\n      <td>37.7400</td>\n      <td>39.1700</td>\n      <td>52.1700</td>\n      <td>30.5800</td>\n      <td>71.7800</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2.409742</td>\n      <td>95.123209</td>\n      <td>45.0</td>\n      <td>10.39255</td>\n      <td>48.802292</td>\n      <td>10.048711</td>\n      <td>41.469914</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>182.600000</td>\n      <td>383.000000</td>\n      <td>367.351852</td>\n      <td>352.000000</td>\n      <td>38.7000</td>\n      <td>41.8900</td>\n      <td>46.9300</td>\n      <td>33.0900</td>\n      <td>76.9700</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>5</td>\n      <td>2</td>\n      <td>2.000000</td>\n      <td>95.000000</td>\n      <td>45.0</td>\n      <td>10.00000</td>\n      <td>50.000000</td>\n      <td>10.000000</td>\n      <td>52.000000</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>163.290763</td>\n      <td>423.558233</td>\n      <td>406.088187</td>\n      <td>388.064257</td>\n      <td>50.8073</td>\n      <td>53.6077</td>\n      <td>49.6062</td>\n      <td>51.6598</td>\n      <td>66.6497</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2.409742</td>\n      <td>95.123209</td>\n      <td>45.0</td>\n      <td>10.39255</td>\n      <td>48.802292</td>\n      <td>10.048711</td>\n      <td>41.469914</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>168.700000</td>\n      <td>384.000000</td>\n      <td>369.811321</td>\n      <td>353.000000</td>\n      <td>49.4700</td>\n      <td>53.0700</td>\n      <td>50.8900</td>\n      <td>55.1000</td>\n      <td>66.4900</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2.409742</td>\n      <td>95.123209</td>\n      <td>45.0</td>\n      <td>10.39255</td>\n      <td>48.802292</td>\n      <td>10.048711</td>\n      <td>41.469914</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>156.600000</td>\n      <td>383.000000</td>\n      <td>367.018868</td>\n      <td>352.000000</td>\n      <td>50.8073</td>\n      <td>53.6077</td>\n      <td>49.6062</td>\n      <td>51.6598</td>\n      <td>66.6497</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>4</td>\n      <td>1</td>\n      <td>40.000000</td>\n      <td>94.000000</td>\n      <td>45.0</td>\n      <td>11.00000</td>\n      <td>45.000000</td>\n      <td>10.000000</td>\n      <td>31.000000</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>163.290763</td>\n      <td>423.558233</td>\n      <td>406.088187</td>\n      <td>388.064257</td>\n      <td>50.8073</td>\n      <td>53.6077</td>\n      <td>49.6062</td>\n      <td>51.6598</td>\n      <td>66.6497</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>5</td>\n      <td>1</td>\n      <td>21.000000</td>\n      <td>87.000000</td>\n      <td>45.0</td>\n      <td>10.00000</td>\n      <td>61.000000</td>\n      <td>10.000000</td>\n      <td>52.000000</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>163.290763</td>\n      <td>423.558233</td>\n      <td>406.088187</td>\n      <td>388.064257</td>\n      <td>50.8073</td>\n      <td>53.6077</td>\n      <td>49.6062</td>\n      <td>51.6598</td>\n      <td>66.6497</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>598 rows × 2596 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.6188375350140056\n"
     ]
    }
   ],
   "source": [
    "hgb = HistGradientBoostingClassifier(random_state=37)\n",
    "\n",
    "# 교차검증\n",
    "scores = cross_validate(hgb, train_x, train_y, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "HistGradientBoostingClassifier(random_state=37)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# 학습시키기\n",
    "hgb.fit(train_x, train_y)\n",
    "#특성중요도 확인\n",
    "# result = permutation_importance(hgb, train_x, train_y, n_repeats=10,random_state=37, n_jobs=-1)\n",
    "# print(result.importances_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# hgb.score(test_input, test_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "preds = hgb.predict(test_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/Users/sola/Downloads/open/sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "submit['Y_Class'] = preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "submit.to_csv('/Users/sola/Downloads/open/baseline_submission6.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "히스토그램 기반 그레이디언트 부스팅 : submission3\n",
    "-> 결측치에 전부 0 입력\n",
    "정확도 0.541749409"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "히스토그램 기반 그레이디언트 부스팅 : submission4\n",
    "-> 결측치에 컬럼별 평균치넣고 아무것도 없는 컬럼에는 0 입력\n",
    "정확도"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "히스토그램 기반 그레이디언트 부스팅 : submission6\n",
    "-> 결측치에 컬럼별 평균치넣고 아무것도 없는 컬럼에는 0 입력 + 평균이 0인 컬럼은 전부 제외함([wrong])\n",
    "정확도 0.4498072733 개형편없넹..!"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
