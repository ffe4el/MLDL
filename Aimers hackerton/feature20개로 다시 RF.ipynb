{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_path = '/Users/sola/Downloads/open/'\n",
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path + 'test.csv')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_3', 'X_6', 'X_14', 'X_70', 'X_74', 'X_75', 'X_76', 'X_77', 'X_78', 'X_79', 'X_82', 'X_83', 'X_84', 'X_85', 'X_142', 'X_190', 'X_191', 'X_192', 'X_193', 'X_194', 'X_195', 'X_232', 'X_234', 'X_235', 'X_259', 'X_260', 'X_315', 'X_319', 'X_322', 'X_323', 'X_324', 'X_327', 'X_328', 'X_329', 'X_330', 'X_375', 'X_376', 'X_377', 'X_378', 'X_427', 'X_466', 'X_467', 'X_505', 'X_508', 'X_558', 'X_561', 'X_567', 'X_583', 'X_617', 'X_620', 'X_631', 'X_633', 'X_634', 'X_636', 'X_638', 'X_639', 'X_640', 'X_641', 'X_642', 'X_672', 'X_673', 'X_676', 'X_691', 'X_692', 'X_695', 'X_715', 'X_729', 'X_732', 'X_743', 'X_749', 'X_759', 'X_760', 'X_761', 'X_764', 'X_776', 'X_777', 'X_778', 'X_836', 'X_843', 'X_844', 'X_849', 'X_859', 'X_886', 'X_887', 'X_888', 'X_889', 'X_934', 'X_935', 'X_936', 'X_937', 'X_992', 'X_1020', 'X_1021', 'X_1022', 'X_1023', 'X_1024', 'X_1025', 'X_1070', 'X_1092', 'X_1119', 'X_1137', 'X_1146', 'X_1206', 'X_1216', 'X_1219', 'X_1248', 'X_1249', 'X_1250', 'X_1251', 'X_1252', 'X_1253', 'X_1255', 'X_1293', 'X_1298', 'X_1309', 'X_1311', 'X_1312', 'X_1314', 'X_1316', 'X_1317', 'X_1318', 'X_1319', 'X_1320', 'X_1361', 'X_1362', 'X_1363', 'X_1364', 'X_1367', 'X_1392', 'X_1393', 'X_1394', 'X_1395', 'X_1396', 'X_1399', 'X_1426', 'X_1457', 'X_1487', 'X_1502', 'X_1503', 'X_1504', 'X_1522', 'X_1531', 'X_1537', 'X_1571', 'X_1572', 'X_1573', 'X_1574', 'X_1575', 'X_1576', 'X_1577', 'X_1578', 'X_1579', 'X_1580', 'X_1581', 'X_1582', 'X_1644', 'X_1645', 'X_1688', 'X_1689', 'X_1692', 'X_1693', 'X_1702', 'X_1722', 'X_1723', 'X_1724', 'X_1754', 'X_1760', 'X_1766', 'X_1772', 'X_1778', 'X_1784', 'X_1790', 'X_1796', 'X_1802', 'X_1808', 'X_1828', 'X_1835', 'X_1836', 'X_1837', 'X_1838', 'X_1839', 'X_1840', 'X_1841', 'X_1842', 'X_1844', 'X_1845', 'X_1846', 'X_1847', 'X_1848', 'X_1851', 'X_1852', 'X_1869', 'X_1870', 'X_1871', 'X_1872', 'X_2052', 'X_2053', 'X_2054', 'X_2055', 'X_2420', 'X_2462', 'X_2628', 'X_2629', 'X_2630', 'X_2631', 'X_2632', 'X_2633', 'X_2634', 'X_2635', 'X_2636', 'X_2637', 'X_2638', 'X_2639', 'X_2640', 'X_2641', 'X_2642', 'X_2643', 'X_2644', 'X_2645', 'X_2646', 'X_2647', 'X_2648', 'X_2649', 'X_2650', 'X_2651', 'X_2652', 'X_2653', 'X_2654', 'X_2655', 'X_2656', 'X_2657', 'X_2658', 'X_2659', 'X_2660', 'X_2661', 'X_2662', 'X_2663', 'X_2664', 'X_2665', 'X_2666', 'X_2667', 'X_2668', 'X_2669', 'X_2670', 'X_2671', 'X_2672', 'X_2673', 'X_2674', 'X_2675', 'X_2676', 'X_2677', 'X_2678', 'X_2679', 'X_2680', 'X_2681', 'X_2682', 'X_2683', 'X_2684', 'X_2685', 'X_2686', 'X_2687', 'X_2688', 'X_2689', 'X_2690', 'X_2691', 'X_2692', 'X_2693', 'X_2694', 'X_2695', 'X_2696', 'X_2697', 'X_2698', 'X_2699', 'X_2733', 'X_2775', 'X_2838', 'X_2844', 'X_2872', 'X_2873', 'X_2874', 'X_2875']\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "# 모든 값이 0인 피처 지울거임..\n",
    "wrong = []\n",
    "for i in range(1,2876):\n",
    "    ch = 'X_'+str(i)\n",
    "    if train[ch].mean() == 0:\n",
    "        wrong.append(ch)\n",
    "\n",
    "print(wrong)\n",
    "print(len(wrong))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train = train.drop(wrong, axis=1)\n",
    "test = test.drop(wrong, axis=1)\n",
    "\n",
    "train = train.drop(['TIMESTAMP','PRODUCT_ID'], axis=1)\n",
    "test = test.drop(['TIMESTAMP','PRODUCT_ID'], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "     Y_Class  Y_Quality     LINE PRODUCT_CODE   X_1   X_2   X_4   X_5   X_7  \\\n0          1   0.533433  T050304         A_31   0.0   0.0   0.0   0.0   0.0   \n1          2   0.541819  T050307         A_31   0.0   0.0   0.0   0.0   0.0   \n2          1   0.531267  T050304         A_31   0.0   0.0   0.0   0.0   0.0   \n3          2   0.537325  T050307         A_31   0.0   0.0   0.0   0.0   0.0   \n4          1   0.531590  T050304         A_31   0.0   0.0   0.0   0.0   0.0   \n..       ...        ...      ...          ...   ...   ...   ...   ...   ...   \n593        1   0.526546  T100306         T_31   2.0  95.0  45.0  10.0  50.0   \n594        0   0.524022  T050304         A_31   0.0   0.0   0.0   0.0   0.0   \n595        0   0.521289  T050304         A_31   0.0   0.0   0.0   0.0   0.0   \n596        1   0.531375  T100304         O_31  40.0  94.0  45.0  11.0  45.0   \n597        1   0.533702  T100306         O_31  21.0  87.0  45.0  10.0  61.0   \n\n      X_8  ...  X_2862  X_2863      X_2864  X_2865  X_2866  X_2867  X_2868  \\\n0     0.0  ...   189.0   383.0  368.296296   353.0   39.34   40.89   32.56   \n1     0.0  ...   185.6   383.0  367.735849   353.0   38.89   42.82   43.92   \n2     0.0  ...   165.5   383.0  367.320755   353.0   39.19   36.65   42.47   \n3     0.0  ...   165.8   384.0  369.188679   353.0   37.74   39.17   52.17   \n4     0.0  ...   182.6   383.0  367.351852   352.0   38.70   41.89   46.93   \n..    ...  ...     ...     ...         ...     ...     ...     ...     ...   \n593  10.0  ...     0.0     0.0    0.000000     0.0    0.00    0.00    0.00   \n594   0.0  ...   168.7   384.0  369.811321   353.0   49.47   53.07   50.89   \n595   0.0  ...   156.6   383.0  367.018868   352.0    0.00    0.00    0.00   \n596  10.0  ...     0.0     0.0    0.000000     0.0    0.00    0.00    0.00   \n597  10.0  ...     0.0     0.0    0.000000     0.0    0.00    0.00    0.00   \n\n     X_2869  X_2870  X_2871  \n0     34.09   77.77     0.0  \n1     35.34   72.55     0.0  \n2     36.53   78.35     0.0  \n3     30.58   71.78     0.0  \n4     33.09   76.97     0.0  \n..      ...     ...     ...  \n593    0.00    0.00     0.0  \n594   55.10   66.49     1.0  \n595    0.00    0.00     1.0  \n596    0.00    0.00     0.0  \n597    0.00    0.00     0.0  \n\n[598 rows x 2598 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Y_Class</th>\n      <th>Y_Quality</th>\n      <th>LINE</th>\n      <th>PRODUCT_CODE</th>\n      <th>X_1</th>\n      <th>X_2</th>\n      <th>X_4</th>\n      <th>X_5</th>\n      <th>X_7</th>\n      <th>X_8</th>\n      <th>...</th>\n      <th>X_2862</th>\n      <th>X_2863</th>\n      <th>X_2864</th>\n      <th>X_2865</th>\n      <th>X_2866</th>\n      <th>X_2867</th>\n      <th>X_2868</th>\n      <th>X_2869</th>\n      <th>X_2870</th>\n      <th>X_2871</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.533433</td>\n      <td>T050304</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>189.0</td>\n      <td>383.0</td>\n      <td>368.296296</td>\n      <td>353.0</td>\n      <td>39.34</td>\n      <td>40.89</td>\n      <td>32.56</td>\n      <td>34.09</td>\n      <td>77.77</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.541819</td>\n      <td>T050307</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>185.6</td>\n      <td>383.0</td>\n      <td>367.735849</td>\n      <td>353.0</td>\n      <td>38.89</td>\n      <td>42.82</td>\n      <td>43.92</td>\n      <td>35.34</td>\n      <td>72.55</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.531267</td>\n      <td>T050304</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>165.5</td>\n      <td>383.0</td>\n      <td>367.320755</td>\n      <td>353.0</td>\n      <td>39.19</td>\n      <td>36.65</td>\n      <td>42.47</td>\n      <td>36.53</td>\n      <td>78.35</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>0.537325</td>\n      <td>T050307</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>165.8</td>\n      <td>384.0</td>\n      <td>369.188679</td>\n      <td>353.0</td>\n      <td>37.74</td>\n      <td>39.17</td>\n      <td>52.17</td>\n      <td>30.58</td>\n      <td>71.78</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0.531590</td>\n      <td>T050304</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>182.6</td>\n      <td>383.0</td>\n      <td>367.351852</td>\n      <td>352.0</td>\n      <td>38.70</td>\n      <td>41.89</td>\n      <td>46.93</td>\n      <td>33.09</td>\n      <td>76.97</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>1</td>\n      <td>0.526546</td>\n      <td>T100306</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>95.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>50.0</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>0</td>\n      <td>0.524022</td>\n      <td>T050304</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>168.7</td>\n      <td>384.0</td>\n      <td>369.811321</td>\n      <td>353.0</td>\n      <td>49.47</td>\n      <td>53.07</td>\n      <td>50.89</td>\n      <td>55.10</td>\n      <td>66.49</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>0</td>\n      <td>0.521289</td>\n      <td>T050304</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>156.6</td>\n      <td>383.0</td>\n      <td>367.018868</td>\n      <td>352.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>1</td>\n      <td>0.531375</td>\n      <td>T100304</td>\n      <td>O_31</td>\n      <td>40.0</td>\n      <td>94.0</td>\n      <td>45.0</td>\n      <td>11.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>1</td>\n      <td>0.533702</td>\n      <td>T100306</td>\n      <td>O_31</td>\n      <td>21.0</td>\n      <td>87.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>61.0</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>598 rows × 2598 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "        LINE PRODUCT_CODE  X_1   X_2   X_4   X_5   X_7   X_8   X_9  X_10  ...  \\\n0    T100306         T_31  2.0  94.0  45.0  10.0  51.0  10.0  52.0   2.0  ...   \n1    T100304         T_31  2.0  93.0  45.0  11.0  45.0  10.0  31.0   2.0  ...   \n2    T100304         T_31  2.0  95.0  45.0  11.0  45.0  10.0  31.0   2.0  ...   \n3    T010305         A_31  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4    T010306         A_31  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n..       ...          ...  ...   ...   ...   ...   ...   ...   ...   ...  ...   \n305  T100306         T_31  2.0  91.0  45.0  10.0  51.0  10.0  52.0   2.0  ...   \n306  T100304         T_31  2.0  96.0  45.0  11.0  45.0  10.0  31.0   2.0  ...   \n307  T100306         T_31  2.0  91.0  45.0  10.0  50.0  10.0  52.0   2.0  ...   \n308  T100306         T_31  2.0  95.0  45.0  10.0  51.0  10.0  52.0   2.0  ...   \n309  T100306         T_31  2.0  87.0  45.0  10.0  51.0  10.0  52.0   2.0  ...   \n\n     X_2862  X_2863      X_2864  X_2865  X_2866  X_2867  X_2868  X_2869  \\\n0       0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n1       0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n2       0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n3     183.8   467.0  444.192308   423.0     0.0     0.0     0.0     0.0   \n4     179.7   465.0  443.211539   423.0     0.0     0.0     0.0     0.0   \n..      ...     ...         ...     ...     ...     ...     ...     ...   \n305     0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n306     0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n307     0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n308     0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n309     0.0     0.0    0.000000     0.0     0.0     0.0     0.0     0.0   \n\n     X_2870  X_2871  \n0       0.0     0.0  \n1       0.0     0.0  \n2       0.0     0.0  \n3       0.0     0.0  \n4       0.0     0.0  \n..      ...     ...  \n305     0.0     0.0  \n306     0.0     0.0  \n307     0.0     0.0  \n308     0.0     0.0  \n309     0.0     0.0  \n\n[310 rows x 2596 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LINE</th>\n      <th>PRODUCT_CODE</th>\n      <th>X_1</th>\n      <th>X_2</th>\n      <th>X_4</th>\n      <th>X_5</th>\n      <th>X_7</th>\n      <th>X_8</th>\n      <th>X_9</th>\n      <th>X_10</th>\n      <th>...</th>\n      <th>X_2862</th>\n      <th>X_2863</th>\n      <th>X_2864</th>\n      <th>X_2865</th>\n      <th>X_2866</th>\n      <th>X_2867</th>\n      <th>X_2868</th>\n      <th>X_2869</th>\n      <th>X_2870</th>\n      <th>X_2871</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>T100306</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>94.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>51.0</td>\n      <td>10.0</td>\n      <td>52.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>T100304</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>93.0</td>\n      <td>45.0</td>\n      <td>11.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>31.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T100304</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>95.0</td>\n      <td>45.0</td>\n      <td>11.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>31.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>T010305</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>183.8</td>\n      <td>467.0</td>\n      <td>444.192308</td>\n      <td>423.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>T010306</td>\n      <td>A_31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>179.7</td>\n      <td>465.0</td>\n      <td>443.211539</td>\n      <td>423.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>T100306</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>91.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>51.0</td>\n      <td>10.0</td>\n      <td>52.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>T100304</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>96.0</td>\n      <td>45.0</td>\n      <td>11.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>31.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>307</th>\n      <td>T100306</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>91.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>50.0</td>\n      <td>10.0</td>\n      <td>52.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>308</th>\n      <td>T100306</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>95.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>51.0</td>\n      <td>10.0</td>\n      <td>52.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>309</th>\n      <td>T100306</td>\n      <td>T_31</td>\n      <td>2.0</td>\n      <td>87.0</td>\n      <td>45.0</td>\n      <td>10.0</td>\n      <td>51.0</td>\n      <td>10.0</td>\n      <td>52.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>310 rows × 2596 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 수치형으로 변환\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train[i])\n",
    "    train[i] = le.transform(train[i])\n",
    "\n",
    "    for label in np.unique(test[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test[i] = le.transform(test[i])\n",
    "print('Done.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_x = train.drop(['Y_Class', 'Y_Quality'], axis=1)\n",
    "y = train['Y_Class']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_x, y, test_size=0.3, random_state=37)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1118 0.017271242607648854\n",
      "X_1405 0.01665629136521816\n",
      "X_1548 0.015383291023175562\n",
      "X_1485 0.015368822370830877\n",
      "X_1091 0.015259603935218323\n",
      "X_1211 0.015125794328482956\n",
      "X_1423 0.014994573148073164\n",
      "X_718 0.014519865145480721\n",
      "X_1500 0.014466255079901414\n",
      "X_1339 0.014464481422528526\n",
      "X_1774 0.014322997487606279\n",
      "X_979 0.014262283990827029\n",
      "X_1834 0.014213057831638475\n",
      "X_240 0.014183563249745007\n",
      "X_1428 0.014157821126726389\n",
      "X_1617 0.01402362084882341\n",
      "X_1198 0.013796140960755056\n",
      "X_1473 0.013764008858550896\n",
      "X_1083 0.013564046427720751\n",
      "X_1475 0.013321541466649656\n",
      "X_1636 0.013204879549014809\n",
      "X_1077 0.01314478461622563\n",
      "X_1849 0.012935785043911945\n",
      "X_1414 0.012915779056259681\n",
      "X_368 0.012817418684700769\n",
      "X_1421 0.012471452410992994\n",
      "X_73 0.012302905566187978\n",
      "X_2846 0.012207599543572109\n",
      "X_1665 0.011951844755341891\n",
      "X_1329 0.011727505415940668\n",
      "X_932 0.01141392264446386\n",
      "X_367 0.011250859431393883\n",
      "X_1161 0.011231592730816982\n",
      "X_665 0.011192212180095083\n",
      "X_318 0.011093391877900599\n",
      "X_1056 0.010984600974371955\n",
      "X_1049 0.010927108314844622\n",
      "X_242 0.010600723915130597\n",
      "X_243 0.010505908112626226\n",
      "X_1117 0.010371815957205452\n",
      "X_1217 0.010270880407466241\n",
      "X_1053 0.01022014474732595\n",
      "X_1145 0.010061506304561055\n",
      "X_964 0.009783786488944802\n",
      "X_1374 0.009750635326006452\n",
      "X_961 0.009712372428881405\n",
      "X_965 0.009618485268474832\n",
      "X_1501 0.00943839273022461\n",
      "X_720 0.00940840754447996\n",
      "X_121 0.009384314513283367\n",
      "X_120 0.009375676499427105\n",
      "X_786 0.00920123125144865\n",
      "X_462 0.009142251956748624\n",
      "X_698 0.00905205426930713\n",
      "X_960 0.008944312849226818\n",
      "X_1032 0.008907122227383692\n",
      "X_835 0.008855352490938799\n",
      "X_258 0.008743263350080754\n",
      "X_1369 0.008709734185610449\n",
      "X_11 0.00844788531279143\n",
      "X_696 0.008340201974489576\n",
      "X_855 0.008307587942296656\n",
      "X_1614 0.008190948243636982\n",
      "X_265 0.008174054083564886\n",
      "X_388 0.008115963165557877\n",
      "X_448 0.008113694559726022\n",
      "X_422 0.008094206254117185\n",
      "X_256 0.008075600776604007\n",
      "X_267 0.007841163416832607\n",
      "X_387 0.00765778513378764\n",
      "X_257 0.0076478607685508985\n",
      "X_492 0.0076470105656346755\n",
      "X_651 0.007532881133210156\n",
      "X_917 0.007487432863259416\n",
      "X_717 0.007458779902594012\n",
      "X_482 0.007417798782083128\n",
      "X_374 0.007383872147749235\n",
      "X_739 0.007336955730682153\n",
      "X_608 0.007237592678930738\n",
      "X_662 0.007180709245192639\n",
      "X_373 0.007156243626912583\n",
      "X_423 0.007119605603481415\n",
      "X_528 0.0071067591646163455\n",
      "X_728 0.007008867015639908\n",
      "X_266 0.006951057885036781\n",
      "X_452 0.006831753077130021\n",
      "X_399 0.006803054895715231\n",
      "X_572 0.006603877028909819\n",
      "X_568 0.006596635852276949\n",
      "X_644 0.006555673959669579\n",
      "X_645 0.006555160108172393\n",
      "X_498 0.00654563694865537\n",
      "X_497 0.006389805000407137\n",
      "X_248 0.006246066173297968\n",
      "X_838 0.006201952036042545\n",
      "X_916 0.006195617988282021\n",
      "X_495 0.006121319812430089\n",
      "X_856 0.005949829672192337\n",
      "X_534 0.0059290508870200685\n",
      "X_307 0.004490730286399391\n",
      "['X_1118', 'X_1405', 'X_1548', 'X_1485', 'X_1091', 'X_1211', 'X_1423', 'X_718', 'X_1500', 'X_1339', 'X_1774', 'X_979', 'X_1834', 'X_240', 'X_1428', 'X_1617', 'X_1198', 'X_1473', 'X_1083', 'X_1475', 'X_1636', 'X_1077', 'X_1849', 'X_1414', 'X_368', 'X_1421', 'X_73', 'X_2846', 'X_1665', 'X_1329', 'X_932', 'X_367', 'X_1161', 'X_665', 'X_318', 'X_1056', 'X_1049', 'X_242', 'X_243', 'X_1117', 'X_1217', 'X_1053', 'X_1145', 'X_964', 'X_1374', 'X_961', 'X_965', 'X_1501', 'X_720', 'X_121', 'X_120', 'X_786', 'X_462', 'X_698', 'X_960', 'X_1032', 'X_835', 'X_258', 'X_1369', 'X_11', 'X_696', 'X_855', 'X_1614', 'X_265', 'X_388', 'X_448', 'X_422', 'X_256', 'X_267', 'X_387', 'X_257', 'X_492', 'X_651', 'X_917', 'X_717', 'X_482', 'X_374', 'X_739', 'X_608', 'X_662', 'X_373', 'X_423', 'X_528', 'X_728', 'X_266', 'X_452', 'X_399', 'X_572', 'X_568', 'X_644', 'X_645', 'X_498', 'X_497', 'X_248', 'X_838', 'X_916', 'X_495', 'X_856', 'X_534', 'X_307']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "feat_labels = X_train.columns\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = -1)\n",
    "# rf= lgb.LGBMClassifier(random_state=37)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# argsort : 리스트 인덱스의 정렬됐을 때의 인덱스 값 반환, [::-1] : 뒤집기\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "\tprint(feat_labels[indices[i]], importances[indices[i]])\n",
    "\n",
    "#상위20개만...\n",
    "a=[]\n",
    "for i in range(100):\n",
    "    a.append(feat_labels[indices[i]])\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9   3   2]\n",
      " [ 12 121  16]\n",
      " [  0   7  10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7777777777777778"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_x = train_x[a]\n",
    "y = train['Y_Class']\n",
    "test_x = test[a]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_x, y, test_size=0.3, random_state=37)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "prediction = rf.predict(X_valid)\n",
    "\n",
    "# rf.score(X_valid, y_valid)\n",
    "print(confusion_matrix(prediction, y_valid))\n",
    "accuracy_score(prediction,y_valid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_jobs = -1 ,random_state=37)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# RF.fit(train_x, y)\n",
    "# rf.\n",
    "preds = rf.predict(test_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/Users/sola/Downloads/open/sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "submit['Y_Class'] = preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "submit.to_csv('/Users/sola/Downloads/open/baseline_submission11.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "피쳐중요도가 상위 20개만 골라서 돌려봄, 랜덤포레스트를 이용함\n",
    "submission7\n",
    "-> 정확도 0.5966049383 129위"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "피쳐중요도가 상위 500개만 골라서 돌려봄, 랜덤포레스트를 이용함\n",
    "submission8\n",
    "-> 정확도 0.5197085927\n",
    "아니 왜내려가...? 검증데이터에서는 올라갔는데..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "피쳐중요도가 상위 100개만 골라서 돌려봄, 랜덤포레스트를 이용함\n",
    "submission9\n",
    "-> 정확도 0.6189786059 109등!!\n",
    "앙 기모리!!!!! 드디어 0.6대로 들어갔다~!!!!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "피쳐중요도가 상위 80개만 골라서 돌려봄, 랜덤포레스트를 이용함\n",
    "submission10\n",
    "-> 정확도"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "피쳐중요도가 상위 100개만 골라서 돌려봄, 랜덤포레스트를 이용함, 근데 feature importance 구한\n",
    "submission11\n",
    "-> 정확도"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
